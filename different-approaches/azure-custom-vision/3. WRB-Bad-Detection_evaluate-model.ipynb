{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to the project directory\n",
    "utils_path = os.path.abspath('..')\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "# Add the path to the directory containing utils to sys.path\n",
    "utils_path = os.path.abspath('../utils')\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate the client\n",
    "\n",
    "Instantiate a training and prediction client with your endpoint and keys. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90dad624b6664556accbcfd69e2e170d https://crackdetection.cognitiveservices.azure.com/\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "print(os.getenv(\"TRAINING_KEY\"), os.getenv(\"TRAINING_ENDPOINT\"))\n",
    "\n",
    "# Authentication\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": os.getenv(\"TRAINING_KEY\")})\n",
    "trainer = CustomVisionTrainingClient(endpoint=os.getenv(\"TRAINING_ENDPOINT\"), credentials=credentials)\n",
    "\n",
    "# Authentication for prediction\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": os.getenv(\"PREDICTION_KEY\")})\n",
    "predictor = CustomVisionPredictionClient(endpoint=os.getenv(\"PREDICTION_ENDPOINT\"), credentials=prediction_credentials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creat or get the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for project 'WRB-Bad-Detection'...\n",
      "Project 'WRB-Bad-Detection' found with ID: 1ee0bb48-3b3f-419d-a575-e12c98f91578\n"
     ]
    }
   ],
   "source": [
    "# Find the object detection domain\n",
    "obj_detection_domain = next(domain for domain in trainer.get_domains() if domain.type == \"ObjectDetection\" and domain.name == \"General\")\n",
    "\n",
    "# Project name setup\n",
    "project_name = \"WRB-Bad-Detection\"\n",
    "\n",
    "# Find project by name\n",
    "print(f\"Searching for project '{project_name}'...\")\n",
    "projects = trainer.get_projects()\n",
    "\n",
    "project_id = None\n",
    "for project in projects:\n",
    "    if project.name == project_name:\n",
    "        project_id = project.id\n",
    "        break\n",
    "\n",
    "if project_id:\n",
    "    print(f\"Project '{project_name}' found with ID: {project_id}\")\n",
    "else:\n",
    "    print(f\"No project found with the name '{project_name}'\")\n",
    "    # Create a new project\n",
    "    print (\"Creating project...\")\n",
    "    project = trainer.create_project(project_name, domain_id=obj_detection_domain.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching iterations for project 'WRB-Bad-Detection'(id:'1ee0bb48-3b3f-419d-a575-e12c98f91578')...\n",
      "Iteration:\n",
      "Iteration 3, Created at 2024-06-29 07:41:11.493000+00:00, Last modified at 2024-06-29 09:13:19.213000+00:00\n",
      "Iteration 2, Created at 2024-06-29 07:19:07.863000+00:00, Last modified at 2024-06-29 07:48:31.821000+00:00\n",
      "Iteration 1, Created at 2024-06-28 20:03:03.686000+00:00, Last modified at 2024-06-29 07:27:01.080000+00:00\n"
     ]
    }
   ],
   "source": [
    "# Get iterations\n",
    "print(f\"Fetching iterations for project '{project_name}'(id:'{project_id}')...\")\n",
    "iterations = trainer.get_iterations(project_id)\n",
    "\n",
    "# List iteration IDs\n",
    "print(\"Iteration:\")\n",
    "for iteration in iterations:\n",
    "    # print(iteration)\n",
    "    print(f\"{iteration.name}, Created at {iteration.created}, Last modified at {iteration.last_modified}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the prediction endpoint\n",
    "To send an image to the prediction endpoint and retrieve the prediction, add the following code to the end of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_iteration_name = \"detectModel\"\n",
    "# Now there is a trained endpoint that can be used to make a prediction\n",
    "\n",
    "# Open the sample image and get back the prediction results.\n",
    "with open(\"test_image.jpg\", mode=\"rb\") as test_image:\n",
    "    results = predictor.detect_image(\n",
    "        project.id, \n",
    "        publish_iteration_name, \n",
    "        test_image)\n",
    "\n",
    "# Display the results.    \n",
    "for prediction in results.predictions:\n",
    "    print(\"\\t\" + prediction.tag_name + \": \\\n",
    "          {0:.2f}% bbox.left = {1:.2f}, bbox.top = {2:.2f}, bbox.width = {3:.2f}, bbox.height = {4:.2f}\"\n",
    "          .format(prediction.probability * 100, \n",
    "                  prediction.bounding_box.left, \n",
    "                  prediction.bounding_box.top, \n",
    "                  prediction.bounding_box.width, \n",
    "                  prediction.bounding_box.height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "# data = pd.read_excel('WRB_trimmed.xlsx')\n",
    "data = pd.read_excel('../dataset/WRB_All.xlsx')\n",
    "\n",
    "# test sets based on the 'Group Name' column\n",
    "test_data = data[data['Group Name'] == 'Test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "Evaluate the model performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training.models import CustomVisionErrorException\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from utils.network_functions import fetch_image\n",
    "import numpy as np\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "\n",
    "    xi1 = max(x1, x2)\n",
    "    yi1 = max(y1, y2)\n",
    "    xi2 = min(x1 + w1, x2 + w2)\n",
    "    yi2 = min(y1 + h1, y2 + h2)\n",
    "\n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "    box1_area = w1 * h1\n",
    "    box2_area = w2 * h2\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    iou = inter_area / union_area\n",
    "    return iou\n",
    "\n",
    "def get_bounding_boxes(points):\n",
    "    x_coords = [p['x'] for p in points]\n",
    "    y_coords = [p['y'] for p in points]\n",
    "    min_x = min(x_coords)\n",
    "    min_y = min(y_coords)\n",
    "    max_x = max(x_coords)\n",
    "    max_y = max(y_coords)\n",
    "    return [min_x, min_y, max_x - min_x, max_y - min_y]\n",
    "\n",
    "def evaluate_model(test_data, predictor, project_id, iteration_id):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for _, row in test_data.iterrows():\n",
    "        img = fetch_image(row['2D Image URL'])\n",
    "        img.save(\"test_image.jpg\")\n",
    "\n",
    "        with open(\"test_image.jpg\", \"rb\") as image_contents:\n",
    "            results = predictor.detect_image(\n",
    "                project.id, \n",
    "                publish_iteration_name, \n",
    "                image_contents.read()\n",
    "                )\n",
    "\n",
    "        ground_truth_boxes = [get_bounding_boxes(eval(row['2D Image Points']))]\n",
    "        predicted_boxes = [[pred.bounding_box.left, pred.bounding_box.top, \n",
    "                            pred.bounding_box.width, pred.bounding_box.height] for pred in results.predictions]\n",
    "\n",
    "        for gt_box in ground_truth_boxes:\n",
    "            max_iou = 0\n",
    "            best_pred_box = None\n",
    "            for pred_box in predicted_boxes:\n",
    "                iou = calculate_iou(gt_box, pred_box)\n",
    "                if iou > max_iou:\n",
    "                    max_iou = iou\n",
    "                    best_pred_box = pred_box\n",
    "            \n",
    "            y_true.append(1)  # There is a ground truth box\n",
    "            y_pred.append(1 if max_iou >= 0.5 else 0)  # Consider it a match if IoU >= 0.5\n",
    "\n",
    "        for pred_box in predicted_boxes:\n",
    "            iou_scores = [calculate_iou(pred_box, gt_box) for gt_box in ground_truth_boxes]\n",
    "            if all(iou < 0.5 for iou in iou_scores):\n",
    "                y_true.append(0)  # There was no matching ground truth box\n",
    "                y_pred.append(1)  # False positive\n",
    "\n",
    "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Evaluate the model\n",
    "for iteration in iterations:\n",
    "    print(f\"{iteration.name}, id: {iteration.id}, Created at {iteration.created}, Last modified at {iteration.last_modified}\")\n",
    "    try:\n",
    "        metrics = evaluate_model(test_data, predictor, project_id, iteration.id)\n",
    "        print(metrics)\n",
    "    except CustomVisionErrorException as e:\n",
    "        print(f\"Custom Vision Error: {e}\")\n",
    "        # Handle specific error scenario (e.g., invalid iteration ID)\n",
    "    except Exception as ex:\n",
    "        print(f\"An unexpected error occurred: {ex}\")\n",
    "        # Handle other exceptions\n",
    "\n",
    "    metrics = evaluate_model(test_data, predictor, project.id, iteration.id)\n",
    "    print(metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Azure-Custom-Vision-Practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
